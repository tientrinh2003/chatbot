#!/usr/bin/env python3
"""
Enhanced SmartBP Chatbot API with SBM Integration
Supports role-based conversations with patient data context
"""

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import os
import logging
import warnings
import shutil
import uuid
import time
import json
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Literal
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
import ollama
from langdetect import detect, LangDetectException
from dotenv import load_dotenv
from fastapi.responses import JSONResponse

# Load environment variables
load_dotenv()

app = FastAPI(title="SmartBP Chatbot API", version="2.0.0")

# CORS configuration
cors_origins = os.getenv("CORS_ORIGINS", "http://localhost:3000,http://127.0.0.1:3000").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
logging.basicConfig(level=logging.INFO)
warnings.filterwarnings("ignore")

DATA_PATH = os.getenv("DATA_DIR", "./data")
MODEL_NAME = os.getenv("LLM_MODEL", "llama3.1:8b")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "nomic-embed-text")
DB_PATH = os.getenv("PERSIST_DIR", "./db")

# Pydantic Models
class UserContext(BaseModel):
    id: str
    name: Optional[str] = None
    email: Optional[str] = None
    role: Literal["PATIENT", "DOCTOR", "ADMIN"]
    dateOfBirth: Optional[str] = None
    gender: Optional[Literal["MALE", "FEMALE", "OTHER"]] = None
    phone: Optional[str] = None

class MeasurementData(BaseModel):
    id: str
    sys: int
    dia: int
    pulse: int
    method: Literal["BLUETOOTH", "MANUAL"]
    takenAt: str
    trend: Optional[Dict[str, Any]] = None

class PatientSummary(BaseModel):
    latest_measurements: List[MeasurementData] = []
    measurement_count: int = 0
    avg_sys: float = 0
    avg_dia: float = 0
    risk_assessment: str = "Unknown"
    recent_notes: Optional[List[str]] = []

class DoctorContext(BaseModel):
    assigned_patients_count: int = 0
    recent_alerts: Optional[List[str]] = []
    pending_reviews: Optional[int] = 0

class SessionMetadata(BaseModel):
    device_info: Optional[str] = None
    location: Optional[str] = None

class ChatContext(BaseModel):
    user: UserContext
    role_specific_data: Optional[Dict[str, Any]] = None
    timestamp: str
    session_metadata: Optional[SessionMetadata] = None

class EnhancedChatRequest(BaseModel):
    message: str
    user_id: str
    conversation_id: Optional[str] = None
    context: ChatContext
    language: Optional[Literal["en", "vi", "auto"]] = "auto"  # New language parameter

class DataInsights(BaseModel):
    mentioned_measurements: bool = False
    health_recommendations: List[str] = []
    follow_up_actions: List[str] = []

class EnhancedChatResponse(BaseModel):
    success: bool
    response: str
    conversation_id: str
    suggestions: Optional[List[str]] = []
    requires_medical_attention: bool = False
    data_insights: Optional[DataInsights] = None
    detected_language: Optional[str] = None  # New field for detected language

# Language detection function
def detect_language(text: str) -> str:
    """Detect language from input text"""
    try:
        detected = detect(text)
        return "en" if detected == "en" else "vi"
    except LangDetectException:
        # Default to Vietnamese if detection fails
        return "vi"

# Enhanced role-specific prompt templates with bilingual support
SYSTEM_TEMPLATES = {
    "PATIENT": {
        "vi": """B·∫°n l√† tr·ª£ l√Ω s·ª©c kh·ªèe c√° nh√¢n c·ªßa {patient_name}, chuy√™n v·ªÅ qu·∫£n l√Ω huy·∫øt √°p.

TH√îNG TIN B·ªÜNH NH√ÇN:
- T√™n: {patient_name}
- Tu·ªïi: {patient_age}
- Huy·∫øt √°p trung b√¨nh g·∫ßn ƒë√¢y: {avg_bp} mmHg
- T·ªïng s·ªë l·∫ßn ƒëo: {measurement_count}
- M·ª©c ƒë·ªô nguy c∆°: {risk_level}
- K·∫øt qu·∫£ ƒëo g·∫ßn nh·∫•t: {recent_measurements}

H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
- LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- G·ªçi t√™n b·ªánh nh√¢n khi ph√π h·ª£p ƒë·ªÉ t·∫°o s·ª± th√¢n thi·ªán
- Tham kh·∫£o d·ªØ li·ªáu huy·∫øt √°p th·ª±c t·∫ø c·ªßa h·ªç khi li√™n quan
- N·∫øu c√≥ tri·ªáu ch·ª©ng nghi√™m tr·ªçng, kh·∫©n c·∫•p khuy√™n ƒëi kh√°m b√°c sƒ© ngay
- ƒê∆∞a ra l·ªùi khuy√™n s·ª©c kh·ªèe c·ª• th·ªÉ d·ª±a tr√™n xu h∆∞·ªõng ƒëo c·ªßa h·ªç
- ƒê·ªông vi√™n v√† h·ªó tr·ª£ t√≠ch c·ª±c trong h√†nh tr√¨nh qu·∫£n l√Ω s·ª©c kh·ªèe

L·ªãch s·ª≠ tr√≤ chuy·ªán: {chat_history}
C∆° s·ªü ki·∫øn th·ª©c y t·∫ø: {context}
C√¢u h·ªèi c·ªßa b·ªánh nh√¢n: {question}
Tr·∫£ l·ªùi c·ªßa tr·ª£ l√Ω s·ª©c kh·ªèe (B·∫∞NG TI·∫æNG VI·ªÜT):""",
        
        "en": """You are a personal health assistant for {patient_name}, specializing in blood pressure management.

PATIENT INFORMATION:
- Name: {patient_name}
- Age: {patient_age}
- Recent average blood pressure: {avg_bp} mmHg
- Total measurements: {measurement_count}
- Risk level: {risk_level}
- Latest readings: {recent_measurements}

IMPORTANT GUIDELINES:
- ALWAYS respond in English
- Address the patient by name when appropriate to create familiarity
- Reference their actual blood pressure data when relevant
- If there are serious symptoms, urgently advise seeing a doctor immediately
- Provide specific health advice based on their measurement trends
- Encourage and provide positive support in their health management journey

Chat history: {chat_history}
Medical knowledge base: {context}
Patient's question: {question}
Health assistant response (IN ENGLISH):"""
    },

    "DOCTOR": {
        "vi": """B·∫°n l√† tr·ª£ l√Ω h·ªó tr·ª£ quy·∫øt ƒë·ªãnh l√¢m s√†ng cho B√°c sƒ© {doctor_name}, chuy√™n v·ªÅ qu·∫£n l√Ω tƒÉng huy·∫øt √°p.

TH√îNG TIN B√ÅC Sƒ®:
- S·ªë b·ªánh nh√¢n ƒë∆∞·ª£c ph√¢n c√¥ng: {patient_count}
- S·ªë ca c·∫ßn xem x√©t: {pending_reviews}
- C·∫£nh b√°o g·∫ßn ƒë√¢y: {recent_alerts}

Khi th·∫£o lu·∫≠n v·ªÅ b·ªánh nh√¢n c·ª• th·ªÉ, h√£y cung c·∫•p:
- Ph√¢n t√≠ch l√¢m s√†ng d·ª±a tr√™n xu h∆∞·ªõng huy·∫øt √°p
- Khuy·∫øn ngh·ªã ph√¢n t·∫ßng nguy c∆°
- ƒê·ªÅ xu·∫•t ƒëi·ªÅu ch·ªânh ƒëi·ªÅu tr·ªã
- Quan s√°t v·ªÅ tu√¢n th·ªß ƒëi·ªÅu tr·ªã c·ªßa b·ªánh nh√¢n
- Khuy·∫øn ngh·ªã l·ªãch t√°i kh√°m

H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
- LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- ƒê∆∞a ra khuy·∫øn ngh·ªã l√¢m s√†ng d·ª±a tr√™n b·∫±ng ch·ª©ng
- Tham kh·∫£o c√°c h∆∞·ªõng d·∫´n v√† giao th·ª©c y t·∫ø
- ƒê·ªÅ xu·∫•t chi·∫øn l∆∞·ª£c theo d√µi b·ªánh nh√¢n c·ª• th·ªÉ
- H·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh l√¢m s√†ng b·∫±ng ph√¢n t√≠ch d·ªØ li·ªáu

L·ªãch s·ª≠ tr√≤ chuy·ªán: {chat_history}
C∆° s·ªü ki·∫øn th·ª©c y t·∫ø: {context}
C√¢u h·ªèi l√¢m s√†ng: {question}
Tr·∫£ l·ªùi h·ªó tr·ª£ quy·∫øt ƒë·ªãnh l√¢m s√†ng (B·∫∞NG TI·∫æNG VI·ªÜT):""",
        
        "en": """You are a clinical decision support assistant for Dr. {doctor_name}, specializing in hypertension management.

DOCTOR INFORMATION:
- Assigned patients count: {patient_count}
- Pending reviews: {pending_reviews}
- Recent alerts: {recent_alerts}

When discussing specific patients, please provide:
- Clinical analysis based on blood pressure trends
- Risk stratification recommendations
- Treatment adjustment suggestions
- Observations on patient treatment compliance
- Follow-up schedule recommendations

IMPORTANT GUIDELINES:
- ALWAYS respond in English
- Provide evidence-based clinical recommendations
- Reference medical guidelines and protocols
- Suggest patient-specific monitoring strategies
- Support clinical decision-making with data analysis

Chat history: {chat_history}
Medical knowledge base: {context}
Clinical question: {question}
Clinical decision support response (IN ENGLISH):"""
    },

    "ADMIN": {
        "vi": """B·∫°n l√† tr·ª£ l√Ω qu·∫£n tr·ªã h·ªá th·ªëng cho n·ªÅn t·∫£ng SmartBP.

NG·ªÆ C·∫¢NH QU·∫¢N TR·ªä:
- Gi√°m s√°t v√† kh·∫Øc ph·ª•c s·ª± c·ªë h·ªá th·ªëng
- Qu·∫£n l√Ω ng∆∞·ªùi d√πng v√† ki·ªÉm so√°t truy c·∫≠p
- Ph√¢n t√≠ch d·ªØ li·ªáu v√† b√°o c√°o
- C·∫•u h√¨nh n·ªÅn t·∫£ng

H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
- LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- Cung c·∫•p th√¥ng tin k·ªπ thu·∫≠t v·ªÅ hi·ªáu su·∫•t h·ªá th·ªëng
- H·ªó tr·ª£ c√°c t√°c v·ª• qu·∫£n l√Ω ng∆∞·ªùi d√πng
- H·ªó tr·ª£ ph√¢n t√≠ch d·ªØ li·ªáu v√† b√°o c√°o
- H·ªó tr·ª£ c·∫•u h√¨nh v√† b·∫£o tr√¨ h·ªá th·ªëng

L·ªãch s·ª≠ tr√≤ chuy·ªán: {chat_history}
C∆° s·ªü ki·∫øn th·ª©c: {context}
C√¢u h·ªèi h·ªá th·ªëng: {question}
Tr·∫£ l·ªùi qu·∫£n tr·ªã h·ªá th·ªëng (B·∫∞NG TI·∫æNG VI·ªÜT):""",
        
        "en": """You are a system administration assistant for the SmartBP platform.

ADMINISTRATIVE CONTEXT:
- System monitoring and troubleshooting
- User management and access control
- Data analysis and reporting
- Platform configuration

IMPORTANT GUIDELINES:
- ALWAYS respond in English
- Provide technical information about system performance
- Support user management tasks
- Assist with data analysis and reporting
- Support system configuration and maintenance

Chat history: {chat_history}
Knowledge base: {context}
System question: {question}
System administration response (IN ENGLISH):"""
    }
}

# Global variables for RAG components
vectorstore = None
conversation_chains = {}

def initialize_rag_system():
    """Initialize the RAG system with medical documents"""
    global vectorstore
    
    try:
        # Initialize embeddings
        embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)
        
        # Load and process documents
        documents = []
        for filename in os.listdir(DATA_PATH):
            file_path = os.path.join(DATA_PATH, filename)
            if filename.endswith('.txt'):
                loader = TextLoader(file_path, encoding='utf-8')
                documents.extend(loader.load())
            elif filename.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
                documents.extend(loader.load())
        
        # Split documents
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        texts = text_splitter.split_documents(documents)
        
        # Create vector store
        vectorstore = Chroma.from_documents(
            documents=texts,
            embedding=embeddings,
            persist_directory=DB_PATH
        )
        
        logging.info(f"‚úÖ Initialized RAG system with {len(texts)} document chunks")
        return True
        
    except Exception as e:
        logging.error(f"‚ùå Failed to initialize RAG system: {e}")
        return False

def analyze_bp_risk(measurements: List[MeasurementData]) -> str:
    """Analyze blood pressure risk based on recent measurements"""
    if not measurements:
        return "Unknown"
    
    recent = measurements[:5]  # Last 5 measurements
    avg_sys = sum(m.sys for m in recent) / len(recent)
    avg_dia = sum(m.dia for m in recent) / len(recent)
    
    if avg_sys >= 180 or avg_dia >= 110:
        return "Critical - Hypertensive Crisis"
    elif avg_sys >= 140 or avg_dia >= 90:
        return "High - Stage 2 Hypertension"
    elif avg_sys >= 130 or avg_dia >= 80:
        return "Elevated - Stage 1 Hypertension"
    elif avg_sys >= 120:
        return "Elevated - Prehypertension"
    else:
        return "Normal"

def format_patient_context(context: ChatContext) -> Dict[str, str]:
    """Format patient context for prompt template"""
    user = context.user
    patient_data = context.role_specific_data or {}
    
    # Calculate age if date of birth provided
    age = "Unknown"
    if user.dateOfBirth:
        try:
            birth_date = datetime.fromisoformat(user.dateOfBirth.replace('Z', '+00:00'))
            age = str(datetime.now().year - birth_date.year)
        except:
            pass
    
    # Format measurements
    measurements = patient_data.get('latest_measurements', [])
    recent_measurements = ""
    if measurements:
        recent_measurements = f"Recent: {measurements[0]['sys']}/{measurements[0]['dia']} mmHg"
    
    return {
        "patient_name": user.name or "Patient",
        "patient_age": age,
        "avg_bp": f"{patient_data.get('avg_sys', 0):.0f}/{patient_data.get('avg_dia', 0):.0f}",
        "measurement_count": str(patient_data.get('measurement_count', 0)),
        "risk_level": patient_data.get('risk_assessment', 'Unknown'),
        "recent_measurements": recent_measurements
    }

def create_conversation_chain(role: str, context: ChatContext, language: str = "vi"):
    """Create a conversation chain for specific role with context and language"""
    if not vectorstore:
        raise HTTPException(status_code=500, detail="RAG system not initialized")
    
    # Get role-specific template based on language
    template = SYSTEM_TEMPLATES.get(role, {}).get(language, SYSTEM_TEMPLATES["PATIENT"]["vi"])
    
    # Format context based on role
    if role == "PATIENT":
        template_vars = format_patient_context(context)
    elif role == "DOCTOR":
        doctor_data = context.role_specific_data or {}
        template_vars = {
            "doctor_name": context.user.name or "Doctor",
            "patient_count": str(doctor_data.get('assigned_patients_count', 0)),
            "pending_reviews": str(doctor_data.get('pending_reviews', 0)),
            "recent_alerts": ", ".join(doctor_data.get('recent_alerts', []) or [])
        }
    else:  # ADMIN
        template_vars = {}
    
    # Create prompt template with partial formatting
    if role == "PATIENT":
        final_template = template.format(
            patient_name=template_vars.get('patient_name', 'Patient'),
            patient_age=template_vars.get('patient_age', 'Unknown'),
            avg_bp=template_vars.get('avg_bp', 'Unknown'),
            measurement_count=template_vars.get('measurement_count', '0'),
            risk_level=template_vars.get('risk_level', 'Unknown'),
            recent_measurements=template_vars.get('recent_measurements', 'None'),
            chat_history="{chat_history}",
            context="{context}",
            question="{question}"
        )
    elif role == "DOCTOR":
        final_template = template.format(
            doctor_name=template_vars.get('doctor_name', 'Doctor'),
            patient_count=template_vars.get('patient_count', '0'),
            pending_reviews=template_vars.get('pending_reviews', '0'),
            recent_alerts=template_vars.get('recent_alerts', 'None'),
            chat_history="{chat_history}",
            context="{context}",
            question="{question}"
        )
    else:  # ADMIN
        final_template = template.format(
            chat_history="{chat_history}",
            context="{context}",
            question="{question}"
        )
    
    prompt = PromptTemplate(
        template=final_template,
        input_variables=["chat_history", "context", "question"]
    )
    
    # Initialize LLM
    llm = ChatOllama(model=MODEL_NAME, temperature=0.7)
    
    # Create conversation chain
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        combine_docs_chain_kwargs={"prompt": prompt}
    )
    
    return chain

@app.on_event("startup")
async def startup_event():
    """Initialize the application"""
    logging.info("üöÄ Starting SmartBP Chatbot API...")
    
    if not os.path.exists(DATA_PATH):
        logging.error(f"‚ùå Data directory not found: {DATA_PATH}")
        return
    
    success = initialize_rag_system()
    if success:
        logging.info("‚úÖ SmartBP Chatbot API is ready!")
    else:
        logging.error("‚ùå Failed to initialize RAG system")

@app.post("/chat", response_model=EnhancedChatResponse)
async def enhanced_chat_endpoint(request: EnhancedChatRequest):
    """Enhanced chat endpoint with full SBM integration and multilingual support"""
    try:
        # Validate request
        if not request.message.strip():
            raise HTTPException(status_code=400, detail="Message cannot be empty")
        
        # Determine language to use
        if request.language == "auto":
            # Auto-detect language from message
            detected_lang = detect_language(request.message)
        else:
            # Use specified language
            detected_lang = request.language or "vi"
        
        # Generate conversation ID if not provided
        conv_id = request.conversation_id or f"{request.user_id}_{int(time.time())}"
        
        # Create conversation chain key with language
        chain_key = f"{conv_id}_{detected_lang}"
        
        # Create or get conversation chain
        if chain_key not in conversation_chains:
            conversation_chains[chain_key] = create_conversation_chain(
                request.context.user.role, 
                request.context,
                detected_lang
            )
        
        chain = conversation_chains[chain_key]
        
        # Process the question
        result = chain({"question": request.message})
        response_text = result["answer"]
        
        # Analyze response for medical urgency (multilingual keywords)
        urgent_keywords = ["kh·∫©n c·∫•p", "ngay l·∫≠p t·ª©c", "emergency", "immediately", "crisis", "urgent"]
        requires_attention = any(keyword in response_text.lower() for keyword in urgent_keywords)
        
        # Generate suggestions based on role and language
        suggestions = []
        if request.context.user.role == "PATIENT":
            if detected_lang == "vi":
                suggestions = [
                    "Xem l·ªãch s·ª≠ ƒëo huy·∫øt √°p",
                    "H∆∞·ªõng d·∫´n ƒëo huy·∫øt √°p ƒë√∫ng c√°ch", 
                    "T∆∞ v·∫•n ch·∫ø ƒë·ªô ƒÉn u·ªëng"
                ]
            else:
                suggestions = [
                    "View blood pressure history",
                    "Blood pressure measurement guide",
                    "Diet and nutrition advice"
                ]
        elif request.context.user.role == "DOCTOR":
            if detected_lang == "vi":
                suggestions = [
                    "Xem b·ªánh nh√¢n c·∫ßn theo d√µi",
                    "Ph√¢n t√≠ch xu h∆∞·ªõng huy·∫øt √°p",
                    "T·∫°o ghi ch√∫ kh√°m b·ªánh"
                ]
            else:
                suggestions = [
                    "View patients requiring monitoring",
                    "Analyze blood pressure trends",
                    "Create clinical notes"
                ]
        
        # Create response
        response = EnhancedChatResponse(
            success=True,
            response=response_text,
            conversation_id=conv_id,
            suggestions=suggestions,
            requires_medical_attention=requires_attention,
            detected_language=detected_lang,
            data_insights=DataInsights(
                mentioned_measurements="huy·∫øt √°p" in request.message.lower() or "blood pressure" in request.message.lower(),
                health_recommendations=[],
                follow_up_actions=[]
            )
        )
        
        return response
        
    except Exception as e:
        logging.error(f"Chat endpoint error: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 5000))  # Use PORT from .env or default to 5000
    uvicorn.run(app, host="0.0.0.0", port=port)